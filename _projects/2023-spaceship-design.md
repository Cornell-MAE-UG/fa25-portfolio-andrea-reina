---
layout: project
title: Holistic Analysis of the Boeing 737 MAX Crashes
description: Engineering ethics and systems analysis of a real-world aviation failure
technologies: [Engineering Ethics, Safety Analysis]
image: /assets/images/boeing.jpg
---

The Boeing 737 MAX crashes can be understood as a wicked problem in engineering because they were caused by many interconnected factors rather than one clear technical failure. From an engineering perspective, the accidents were not simply the result of a faulty system or human error, but rather of the interaction between technical design, organizational decision-making, regulatory oversight, and ethical assumptions. Wicked problems are challenging because they lack a single, well-defined solution, and the Boeing 737 MAX crisis exemplifies this description. Changes made to improve efficiency or competitiveness affected safety, training, and communication, showing how tightly connected the system was. This case makes it clear that engineering problems often exist within complex sociotechnical systems rather than purely technical ones.

At the center of the crashes was the Maneuvering Characteristics Augmentation System, or MCAS, which was designed to automatically adjust the aircraftâ€™s pitch under certain conditions. MCAS relied on information from a single angle of attack sensor, and when that sensor failed, the system repeatedly pushed the nose of the aircraft downward. While this design may have met existing certification requirements, it depended on assumptions that pilots would quickly recognize the issue and respond correctly under intense pressure. These assumptions did not match real flight conditions. This shows how technology is not neutral or inevitable, but shaped by human choices and priorities. MCAS was created partly to allow the aircraft to handle similarly to previous 737 models, reducing the need for additional pilot training. This decision was influenced by competition and cost, demonstrating how economic and organizational factors directly shape engineering design.

The Boeing case also highlights the dangers of fragmented expert knowledge. Different teams were responsible for software development, safety analysis, training, and certification, but these groups did not always fully communicate or understand how their work interacted. As a result, risks that emerged from system interactions were not fully recognized. This lack of integration shows why engineering cannot be separated from its social context. When knowledge is fragmented, responsibility becomes unclear, and safety issues can be overlooked. The case challenges the assumption that as long as each team does its job correctly, the overall system will be safe. In reality, safety depends on how well all parts of the system work together.

Regulation and standardization played an important but complicated role in the 737 MAX crisis. Aviation is heavily regulated, and standards exist to protect public safety, but the certification process allowed Boeing to evaluate parts of its own design through delegated authority. This created a situation where regulatory compliance did not necessarily guarantee safety. This raises important ethical questions about whether laws alone are sufficient to guide responsible engineering behavior. The Boeing case suggests that ethical engineering requires more than following regulations. Engineers must also question whether minimum standards are enough, especially when public lives are at risk. The pressure to compete and maintain profits further complicated decision-making, making it harder for safety concerns to take priority within the organization.

Conducting an ethical analysis of the Boeing 737 MAX case reveals how common engineering assumptions can have serious ethical consequences. Assumptions about pilot behavior, automation reliability, and rare failure conditions shaped critical design decisions. Initially, it may be easy to view the crashes as isolated failures, but deeper analysis shows how organizational culture, communication breakdowns, and regulatory structure all contributed. This process changed my understanding of the case by shifting the focus from individual blame to systemic responsibility. To address ethical dilemmas like this, engineers need strong communication skills, systems thinking, and the ability to identify stakeholders and potential harms early. Using structured ethical frameworks, such as identifying ethical issues before narrowing technical focus, is a tool I would rely on in my future career.

Finally, the Boeing 737 MAX crashes show how trust in engineering can be lost when safety is not clearly prioritized. Trust depends on the expectation that engineers and organizations will act responsibly and in the best interest of the public. When leadership decisions conflict with professional or stakeholder values, engineers have a responsibility to speak up and advocate for safer alternatives. The Boeing case demonstrates why ethics must be integrated into engineering practice from the beginning, not treated as an afterthought once failures occur.
